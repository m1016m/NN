{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#![title](img/picture.png)\n",
    "#在机器学习中，分类问题中的某个类别叫作类（class）。数据点叫作样本（sample）。某个样本对应的类叫作标签（label）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  3  6 14  7]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 向量（1D 张量）\n",
    "# 数字组成的数组叫作向量（vector）或一维张量（1D 张量）。一维张量只有一个轴。下面是一个Numpy 向量。\n",
    "import numpy as np\n",
    "x = np.array([12, 3, 6, 14, 7])\n",
    "\n",
    "# 这个向量有5 个元素，所以被称为5D 向量。不要把5D 向量和5D 张量弄混！ 5D 向量只有一个轴，沿着轴有5 个维度，而5D 张量有5 个轴\n",
    "# （沿着每个轴可能有任意个维度）\n",
    "print(x)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "# 向量组成的数组叫作矩阵（matrix）或二维张量（2D 张量）。矩阵有2 个轴（通常叫作行和列）。你可以将矩阵直观地理解为数字组成的矩形网格。\n",
    "# 下面是一个Numpy 矩阵。\n",
    "x = np.array([[5, 78, 2, 34, 0],[6, 79, 3, 35, 1],[7, 80, 4, 36, 2]])\n",
    "print(x.ndim)\n",
    "print(x.shape)\n",
    "#第一个轴上的元素叫作列（column），第二个轴上的元素叫作行（row）。在上面的例子中，[5, 78, 2, 34, 0] 是x 的第一列，[5, 6, 7] 是第一行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow用張量這種數據結構來表示所有的數據.你可以把一個張量想像成一個n維的數組或列表.一個張量有一個靜態類型和動態類型的維數.\n",
    "# 張量可以在圖中的節點之間流通.\n",
    "\n",
    "# 在TensorFlow系統中，張量的維數來被描述為階.但是張量的階和矩陣的階並不是同一個概念.張量的階（有時是關於如順序或度數或者是n維）是張量維數\n",
    "# 的一個數量描述.比如，下面的張量（使用Python中list定義的）就是2階.\n",
    "\n",
    "# t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "# 你可以認為一個二階張量就是我們平常所說的矩陣，一階張量可以認為是一個向量.對於一個二階張量你可以用語句t[i, j]來訪問其中的任何元素.而對於\n",
    "# 三階張量你可以用't[i, j, k]'來訪問其中的任何元素.\n",
    "\n",
    "# 阶\t数学实例\tPython 例子\n",
    "# 0\t纯量 (只有大小)\ts = 483\n",
    "# 1\t向量(大小和方向)\tv = [1.1, 2.2, 3.3]\n",
    "# 2\t矩阵(数据表)\tm = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "# 3\t3阶张量 (数据立体)\tt = [[[2], [4], [6]], [[8], [10], [12]], [[14], [16], [18]]]\n",
    "\n",
    "# 張量是所有深度學習框架中最核心的組件，因為後續的所有運算和優化算法都是基於張量進行的。 幾何代​​數中定義的張量是基於向量和矩陣的推廣，通俗一點\n",
    "# 理解的話，我們可以將純量視為零階張量，向量視為一階張量，那麼矩陣就是二階張量。\n",
    "\n",
    "# 舉例來說，我們可以將任意一張RGB彩色圖片表示成一個三階張量（三個維度分別是圖片的高度、寬度和色彩數據）。 如下圖所示是一張普通的水果圖片，按照\n",
    "# RGB三原色表示，其可以拆分為三張紅色、綠色和藍色的灰度圖片，如果將這種表示方法用張量的形式寫出來，就是圖中最下方的那張表格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/27.png)\n",
    "![title](img/29.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=int32) Tensor(\"Const_1:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 張量(Tensor)\n",
    "# tensorflow運算中最基本的單位，通常是高維度的矩陣，舉個例子如果我們需要一個可以拿來做圖像辨識的Model，Input的圖片即可用一個2維的tensor表示\n",
    "# ，圖上的每個像素(pixel)都是tensor中的element，同樣的方式也可以用三維的張量來表示一張彩色的圖，第三個維度長度就是3分別代表RGB三原色在現在\n",
    "# 這個(x,y)位置的pixel的值。\n",
    "\n",
    "# 張量的型態主要有三種Constant、Variable、Placeholder\n",
    "\n",
    "# 如果有寫過其他程式語言的應該可以很輕易地了解Constant 和 Variable的意義，沒學過也沒關係，可以就如字面上的意義了解Constant就是不可變的常數\n",
    "# 、Variable即是變數，Placeholder則是tensorflow中比較特別的概念，創建Tensor的方式也很簡單\n",
    "\n",
    "import tensorflow as tf\n",
    "node1 = tf.constant(3) # 常數3的tensor\n",
    "node2 = tf.constant(4) # 常數4的tensor\n",
    "print(node1, node2)\n",
    "\n",
    "# 我們來看看print出來的結果\n",
    "\n",
    "# Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4]\n"
     ]
    }
   ],
   "source": [
    "# node1、node2 分別代表了兩個Const和Tensor，還可以注意到如果我們沒有特別指定data type，default是使用float32作為初始值，但為什麼我們\n",
    "# 看不到我們賦予這兩個tensor的值(3、4)呢?\n",
    "# 這時候我們就必須執行下面這段程式碼\n",
    "\n",
    "sess = tf.Session() # 創建一個tensorflow session\n",
    "print(sess.run([node1, node2])) # 把node1 node2丟進session中run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 運算圖(Computational Graph)\n",
    "# 在開始之前我們先理解一下Tensorflow主要的運作流程分為以下兩個部分\n",
    "\n",
    "# 建立運算圖(Build)\n",
    "# 其實這個部分就是所謂的建立模型(Build Model)，決定整個運算流程，這也是tensorflow和其他框架最大的不同，我們必須事先定義好Graph的長相，\n",
    "# 舉下圖為例，如果想用tensorflow算 3+4=7 那我們該怎麼做呢？首先我們要先建立一個用來做加法運算的Graph如下圖，就是把兩個Constant的tensor\n",
    "# 做一個加法的運算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/30.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3:  Tensor(\"Add:0\", shape=(), dtype=int32)\n",
      "sess.run(node3):  7\n"
     ]
    }
   ],
   "source": [
    "node3 = tf.add(node1, node2) # 把前面創建的const tensor node1、node2相加\n",
    "print(\"node3: \", node3) # node3就是相加後的結果\n",
    "print(\"sess.run(node3): \",sess.run(node3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Placeholder\n",
    "# 正如上面所提到，在Tensorflow中我們都是先建好Graph再決定資料的input與output，這時候我們就需要Placeholder來幫助我們在還沒有資料的時候先佔\n",
    "# 個位子(正如其名)。\n",
    "\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # 這行等效於 adder_node = tf.add(a, b)\n",
    "print(adder_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/31.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "# 用Placeholder實作的程式碼，跟前面用兩個Const Tensor相加最大的區別就是我們這邊並沒有賦予a、b任何值，而只是建立了一個讓a跟b兩個Tensor相加\n",
    "# 的Graph。\n",
    "\n",
    "print(sess.run(adder_node, {a: 3, b:4.5}))\n",
    "# >> 7.5\n",
    "# 接著我們當然又是找session幫我們執行這個Graph，可以看到在sess.run的參數中我們除了第一個參數指定了這次要run的Output外，在第二個參數我們\n",
    "# 給了一個dictionary，這就是我們這次run的過程賦予a和b兩個Placeholder的值，因此adder_node的計算就會根據我們feed進去的資料作改變，在這邊\n",
    "# 很顯然的答案就是3+4.5=7.5。\n",
    "\n",
    "print(sess.run(adder_node, {a: [1,3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "[4 3]\n",
      "12\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_data = tf.constant([1,3,4,6])\n",
    "\n",
    "rank_input_data = tf.rank(input_data)\n",
    "result = tf.argmax(input_data,0)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(rank_input_data))\n",
    "    print(sess.run(result))\n",
    "\n",
    "t = tf.constant([[1, 1, 1], [2, 2, 2], [3, 3, 3], [4, 4, 4]])\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(tf.shape(t)))\n",
    "print(sess.run(tf.size(t)))\n",
    "print(sess.run(tf.rank(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3024, 4032, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10b7580f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "I = mpimg.imread('20.jpg')\n",
    "print (I.shape)\n",
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#为了具体说明，我们回头看一下MNIST 例子中处理的数据。首先加载MNIST 数据集\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#接下来，我们给出张量train_images 的轴的个数，即ndim 属性。\n",
    "print(train_images.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#下面是它的形状。\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "#下面是它的数据类型，即dtype 属性。\n",
    "print(train_images.dtype)\n",
    "\n",
    "# 这里train_images 是一个由8 位整数组成的3D 张量。更确切地说，它是60000,个矩阵组成的数组，每个矩阵由28×28 个整数组成。每个这样的矩阵都是\n",
    "# 一张灰度图像，元素取值范围为0~255。(60000 , 28 ,28 ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#我们用Matplotlib 库（Python 标准科学套件的一部分）来显示这个3D 张量中的第4 个数字\n",
    "digit = train_images[4]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 在Numpy 中操作张量\n",
    "# 张量切片（tensor slicing）。我们来看一下Numpy 数组上的张量切片运算。下面这个例子选择第10~100 个数字（不包括第100 个），并将其放在形状\n",
    "# 为(90, 28,28) 的数组中。\n",
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#等同于下面这个更复杂的写法，给出了切片沿着每个张量轴的起始索引和结束索引。\n",
    "#注意，: 等同于选择整个轴。\n",
    "my_slice = train_images[10:100, :, :]\n",
    "print(my_slice.shape)\n",
    "#(90, 28, 28)\n",
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "print(my_slice.shape)\n",
    "#(90, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[240 253 253 ...   0   0   0]\n",
      "  [ 45 186 253 ...   0   0   0]\n",
      "  [  0  16  93 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[241 243 234 ...   0   0   0]\n",
      "  [143  91  28 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[253 254 253 ...   0   0   0]\n",
      "  [ 72 192 254 ...   0   0   0]\n",
      "  [  0   6 242 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[  0  31 127 ...   0   0   0]\n",
      "  [ 27 218 252 ...   0   0   0]\n",
      "  [194 253 217 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[ 97 254 252 ...   0   0   0]\n",
      "  [232 181  60 ...   0   0   0]\n",
      "  [ 46   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]]\n",
      "(60000, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "#一般来说，你可以沿着每个张量轴在任意两个索引之间进行选择。例如，你可以在所有图像的右下角选出14 像素×14 像素的区域：\n",
    "my_slice = train_images[:, 14:, 14:]\n",
    "print(my_slice)\n",
    "\n",
    "#也可以使用负数索引。与Python 列表中的负数索引类似，它表示与当前轴终点的相对位置。你可以在图像中心裁剪出14 像素×14 像素的区域：\n",
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现实世界中的数据张量\n",
    "# 我们用几个你未来会遇到的示例来具体介绍数据张量。你需要处理的数据几乎总是以下类别之一。\n",
    "\n",
    "#  向量数据：2D 张量，形状为 (samples, features)。\n",
    "#   我们来看两个例子。\n",
    "#      人口统计数据集，其中包括每个人的年龄、邮编和收入。每个人可以表示为包含 3 个值的向量，而整个数据集包含100000 个人，因此可以存储在形状\n",
    "#       为(100000, 3) 的2D张量中。\n",
    "#      文本文档数据集，我们将每个文档表示为每个单词在其中出现的次数（字典中包含20000 个常见单词）。每个文档可以被编码为包含20000 个值的向量\n",
    "#      （每个值对应于字典中每个单词的出现次数），整个数据集包含500 个文档，因此可以存储在形状为(500, 20000) 的张量中。\n",
    "#  时间序列数据或序列数据：3D 张量，形状为 (samples, timesteps, features)。\n",
    "#  图像：4D张量，形状为(samples, height, width, channels)或(samples, channels,height, width)。\n",
    "#  视频：5D张量，形状为(samples, frames, height, width, channels)或(samples,frames, channels, height, width)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间序列数据或序列数据\n",
    "# 当时间（或序列顺序）对于数据很重要时，应该将数据存储在带有时间轴的3D 张量中。每个样本可以被编码为一个向量序列（即2D 张量），因此一个数据批\n",
    "# 量就被编码为一个3D 张量（见图）。\n",
    "\n",
    "# 根据惯例，时间轴始终是第2 个轴（索引为1 的轴）。我们来看几个例子。\n",
    "#  股票价格数据集。每一分钟，我们将股票的当前价格、前一分钟的最高价格和前一分钟的最低价格保存下来。因此每分钟被编码为一个3D 向量，整个交易日\n",
    "#   被编码为一个形状为(390, 3) 的2D 张量（一个交易日有390 分钟），而250 天的数据则可以保存在一个形状为(250, 390, 3) 的3D 张量中。\n",
    "#   这里每个样本是一天的股票数据。(3就是股票的当前价格、前一分钟的最高价格和前一分钟的最低价格)\n",
    "#  推文数据集。我们将每条推文编码为 280 个字符组成的序列，而每个字符又来自于 128个字符组成的字母表。在这种情况下，每个字符可以被编码为大小\n",
    "#   为128 的二进制向量（只有在该字符对应的索引位置取值为1，其他元素都为0）。那么每条推文可以被编码为一个形状为(280, 128) 的2D 张量，而包\n",
    "#   含100 万条推文的数据集则可以存储在一个形状为(1000000, 280, 128) 的张量中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/32.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像数据\n",
    "# 图像通常具有三个维度：高度、宽度和颜色深度。虽然灰度图像（比如MNIST 数字图像）只有一个颜色通道，因此可以保存在2D 张量中，但按照惯例，图像\n",
    "# 张量始终都是3D 张量，灰度图像的彩色通道只有一维。因此，如果图像大小为256×256，那么128 张灰度图像组成的批量可以保存在一个形状为\n",
    "# (128, 256, 256, 1) 的张量中，而128 张彩色图像组成的批量则可以保存在一个形状为(128, 256, 256, 3) 的张量中（见图）\n",
    "\n",
    "# 图像张量的形状有两种约定：通道在后（channels-last）的约定（在TensorFlow 中使用）和通道在前（channels-first）的约定（在Theano 中使用)\n",
    "# Google 的TensorFlow 机器学习框架将颜色深度轴放在最后：(samples, height, width, color_depth)。与此相反，\n",
    "# Theano将图像深度轴放在批量轴之后：(samples, color_depth, height, width)。如果采用Theano 约定，前面的两个例子将变成\n",
    "# (128, 1, 256, 256) 和(128, 3, 256, 256)。Keras 框架同时支持这两种格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/33.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 视频数据\n",
    "# 视频数据是现实生活中需要用到5D 张量的少数数据类型之一。视频可以看作一系列帧，每一帧都是一张彩色图像。由于每一帧都可以保存在一个形状为\n",
    "# (height, width, color_depth) 的3D 张量中，因此一系列帧可以保存在一个形状为(frames, height, width,color_depth) 的4D 张量中，\n",
    "# 而不同视频组成的批量则可以保存在一个5D 张量中，其形状为(samples, frames, height, width, color_depth)。\n",
    "\n",
    "# 举个例子，一个以每秒4 帧采样的60 秒YouTube 视频片段，视频尺寸为144×256，这个视频共有240 帧。4 个这样的视频片段组成的批量将保存在形状为\n",
    "# (4, 240, 144, 256, 3)的张量中。总共有 106168320 个值！如果张量的数据类型（dtype）是float32，每个值都是32 位，那么这个张量共有405MB\n",
    "# 。好大！你在现实生活中遇到的视频要小得多，因为它们不以float32 格式存储，而且通常被大大压缩，比如MPEG 格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#dot圖解\n",
    "![title](img/34.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原则：\n",
    "# (a, b, c, d) . (d,) -> (a, b, c)\n",
    "# (a, b, c, d) . (d, e) -> (a, b, c, e) 以此类推。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]]\n",
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "# 张量变形\n",
    "# 第三个重要的张量运算是张量变形（tensor reshaping）。虽然前面神经网络第一个例子的Dense 层中没有用到它，但在将图像数据输入神经网络之前，\n",
    "# 我们在预处理时用到了这个运算。（reshape）\n",
    "# train_images = train_images.reshape((60000, 28 * 28))\n",
    "\n",
    "# 张量变形是指改变张量的行和列，以得到想要的形状。变形后的张量的元素总个数与初始张量相同\n",
    "import numpy as np\n",
    "x = np.array([[0., 1.],[2., 3.],[4., 5.]])\n",
    "print(x.shape)\n",
    "#(3, 2)\n",
    "\n",
    "x = x.reshape((6, 1))\n",
    "print(x)\n",
    "#array([[ 0.],[ 1.],[ 2.],[ 3.],[ 4.],[ 5.]])\n",
    "\n",
    "x = x.reshape((2, 3))\n",
    "print(x)\n",
    "#array([[ 0., 1., 2.],[ 3., 4., 5.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "#還有一种特殊的张量变形是转置（transposition）。对矩阵做转置是指将行和列互换，使x[i, :] 变为x[:, i]\n",
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "print(x.shape)\n",
    "#(20, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Keras、TensorFlow、Theano 和CNTK\n",
    "![title](img/35.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow、CNTK 和Theano 是当今深度学习的几个主要平台。Theano 由蒙特利尔大学的MILA 实验室开发，TensorFlow 由Google 开发，CNTK \n",
    "# 由微软开发。你用Keras 写的每一段代码都可以在这三个后端上运行，无须任何修改。也就是说，你在开发过程中可以在两个后端之间无缝切换，这通常是很\n",
    "# 有用的\n",
    "# 通过TensorFlow（或Theano、CNTK），Keras 可以在CPU 和GPU 上无缝运行。在CPU 上运行时，TensorFlow 本身封装了一个低层次的张量运算库，\n",
    "# 叫作Eigen；在GPU 上运行时，TensorFlow封装了一个高度优化的深度学习运算库，叫作NVIDIA CUDA 深度神经网络库（cuDNN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#开始使用 Keras Sequential 顺序模型\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "#使用 .add() 方法将各层添加到模型中\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定输入数据的尺寸\n",
    "\n",
    "# 模型需要知道它所期望的输入的尺寸。出于这个原因，顺序模型中的第一层（且只有第一层，因为下面的层可以自动地推断尺寸）需要接收关于其输入尺寸的信息\n",
    "# 有几种方法来做到这一点：\n",
    "\n",
    "# 1. 传递一个 input_shape 参数给第一层,在 input_shape 中指定大小。\n",
    "# 2. Dense，可以透過过参数 input_dim 指定输入尺寸， input_dim 和 input_length 参数都可以。以下兩種寫法都可以\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(784,)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型编译\n",
    "# 在训练模型之前，您需要配置学习过程，这是通过 compile 方法完成的\n",
    "\n",
    "# 优化器 optimizer。如 rmsprop 或 adagrad，也可以是 Optimizer 类的实例。详见：optimizers。\n",
    "\n",
    "# 损失函数 loss，模型试图最小化的目标函数。它可以是现有损失函数的字符串标识符，如 categorical_crossentropy 或 mse。\n",
    "\n",
    "# 评估标准 metrics。对于任何分类问题，你都希望将其设置为 metrics = ['accuracy']。\n",
    "\n",
    "# 多分类问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 二分类问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 均方误差回归问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "# 自定义评估标准函数\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7069 - acc: 0.5020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 130us/step - loss: 0.6959 - acc: 0.5250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 123us/step - loss: 0.6925 - acc: 0.5310\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 141us/step - loss: 0.6899 - acc: 0.5200\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 133us/step - loss: 0.6851 - acc: 0.5590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 130us/step - loss: 0.6813 - acc: 0.5650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 125us/step - loss: 0.6801 - acc: 0.5640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.6735 - acc: 0.5930\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 138us/step - loss: 0.6709 - acc: 0.5870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 126us/step - loss: 0.6666 - acc: 0.6050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb36e6fe80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练\n",
    "# Keras 模型在输入数据和标签的 Numpy 矩阵上进行训练。为了训练一个模型，你通常会使用 fit 函数\n",
    "# 对于具有 2 个类的单输入模型（二进制分类）：\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.3804 - acc: 0.0840\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 112us/step - loss: 2.3319 - acc: 0.1090\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 157us/step - loss: 2.3192 - acc: 0.1020\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 2.3084 - acc: 0.1160\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 2.2975 - acc: 0.1200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 139us/step - loss: 2.2895 - acc: 0.1240\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 146us/step - loss: 2.2802 - acc: 0.1410\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 2.2719 - acc: 0.1420\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 149us/step - loss: 2.2634 - acc: 0.1280\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 135us/step - loss: 2.2519 - acc: 0.1590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb37b5da58>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于具有 10 个类的单输入模型（多分类分类）：\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# 将标签转换为分类的 one-hot 编码\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "1\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "#IMDB 数据集\n",
    "# 它包含来自互联网电影数据库（IMDB）的50000 条严重两极分化的评论。数据集被分为用于训练的25000 条评论与用于测试的25000 条评论，训练集和测试\n",
    "# 集都包含50% 的正面评论和50% 的负面评论\n",
    "\n",
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# 参数num_words=10000 的意思是仅保留训练数据中前10000 个最常出现的单词。低频单词将被舍弃。这样得到的向量数据不会太大，便于处理。\n",
    "# train_data 和test_data 这两个变量都是评论组成的列表，每条评论又是单词索引组成的列表（表示一系列单词）。\n",
    "# train_labels 和test_labels 都是0 和1 组成的列表，其中0代表负面（negative），1 代表正面（positive）。\n",
    "\n",
    "print(train_data[0])\n",
    "#[1, 14, 22, 16, ... 178, 32]\n",
    "\n",
    "print(train_labels[0])\n",
    "#1\n",
    "\n",
    "#由于限定为前10000 个最常见的单词，单词索引都不会超过10000。\n",
    "print(max([max(sequence) for sequence in train_data]))\n",
    "#9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "# 你不能将整数序列直接输入神经网络。你需要将列表转换为张量。转换方法有以下两种。\n",
    "#  填充列表，使其具有相同的长度，再将列表转换成形状为 (samples, word_indices)的整数张量，然后网络第一层使用能处理这种整数张量的层\n",
    " \n",
    "#  对列表进行 one-hot 编码，将其转换为 0 和 1 组成的向量。举个例子，序列[3, 5]将会被转换为10 000 维向量，只有索引为3 和5 的元素是1\n",
    "#  ，其余元素都是0。然后网络第一层可以用Dense 层，它能够处理浮点数向量数据。\n",
    "\n",
    "# enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。\n",
    "\n",
    "# enumerate(sequence, [start=0])\n",
    "\n",
    "# 参数\n",
    "# sequence -- 一个序列、迭代器或其他支持迭代对象。\n",
    "# start -- 下标起始位置。\n",
    "\n",
    "\n",
    "# 实例\n",
    "# 以下展示了使用 enumerate() 方法的实例：\n",
    "\n",
    "# >>>seasons = ['Spring', 'Summer', 'Fall', 'Winter']\n",
    "# >>> list(enumerate(seasons))\n",
    "# [(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]\n",
    "# >>> list(enumerate(seasons, start=1))       # 下标从 1 开始\n",
    "# [(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))#创建一个形状为(len(sequences),dimension) 的全部都是零矩阵\n",
    "    #print(results)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.#将results[i] 的指定索引设为1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)#将训练数据向量化\n",
    "x_test = vectorize_sequences(test_data)#将测试数据向量化\n",
    "\n",
    "#样本现在变成了这样：\n",
    "print(x_train[0])\n",
    "#array([ 0., 1., 1., ..., 0., 0., 0.])\n",
    "\n",
    "#你还应该将标签向量化，这很简单。\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "#现在可以将数据输入到神经网络中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在可以将数据输入到神经网络中\n",
    "# 构建网络\n",
    "# 输入数据是向量，而标签是标量（1 和0），这是你会遇到的最简单的情况。有一类网络在这种问题上表现很好，就是带有relu 激活的全连接层（Dense）\n",
    "# 的简单堆叠，比如\n",
    "# Dense(16, activation='relu')。\n",
    "# 传入Dense 层的参数（16）是该层隐藏单元的个数。一个隐藏单元（hidden unit）是该层表示空间的一个维度。我们在第2 章讲过，每个带有relu\n",
    "# 激活的Dense 层都实现了下列张量运算：如圖"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/36.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型定义\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你需要选择损失函数和优化器。由于你面对的是一个二分类问题，网络输出是一个概率值（网络最后一层使用sigmoid 激活函数，仅包含一个单元），\n",
    "# 那么最好使用binary_crossentropy（二元交叉熵）损失。这并不是唯一可行的选择，比如你还可以使用mean_squared_error（均方误差）。\n",
    "# 但对于输出概率值的模型，交叉熵（crossentropy）往往是最好的选择。交叉熵是来自于信息论领域的概念，用于衡量概率分布之间的距离，在这个例子中就\n",
    "# 是真实分布与预测值之间的距离。\n",
    "#编译模型\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#配置优化器\n",
    "from keras import optimizers\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用自定义的损失和指标\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),loss=losses.binary_crossentropy,metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证你的方法\n",
    "# 为了在训练过程中监控模型在前所未见的数据上的精度，你需要将原始训练数据留出10000个样本作为验证集。留出验证集\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 4s 271us/step - loss: 0.5084 - acc: 0.7813 - val_loss: 0.3797 - val_acc: 0.8684\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 2s 107us/step - loss: 0.3004 - acc: 0.9047 - val_loss: 0.3004 - val_acc: 0.8897\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 0.2179 - acc: 0.9285 - val_loss: 0.3085 - val_acc: 0.8711\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.1750 - acc: 0.9437 - val_loss: 0.2840 - val_acc: 0.8832\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.1427 - acc: 0.9543 - val_loss: 0.2841 - val_acc: 0.8872\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1150 - acc: 0.9650 - val_loss: 0.3166 - val_acc: 0.8772\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0980 - acc: 0.9705 - val_loss: 0.3127 - val_acc: 0.8846\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0807 - acc: 0.9763 - val_loss: 0.3859 - val_acc: 0.8649\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0661 - acc: 0.9821 - val_loss: 0.3635 - val_acc: 0.8782\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0561 - acc: 0.9853 - val_loss: 0.3843 - val_acc: 0.8792\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0439 - acc: 0.9893 - val_loss: 0.4153 - val_acc: 0.8779\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0381 - acc: 0.9921 - val_loss: 0.4525 - val_acc: 0.8690\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0300 - acc: 0.9928 - val_loss: 0.4698 - val_acc: 0.8729\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0247 - acc: 0.9945 - val_loss: 0.5023 - val_acc: 0.8725\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 2s 108us/step - loss: 0.0176 - acc: 0.9980 - val_loss: 0.5335 - val_acc: 0.8693\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0152 - acc: 0.9983 - val_loss: 0.5720 - val_acc: 0.8697\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0144 - acc: 0.9969 - val_loss: 0.6033 - val_acc: 0.8699\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0093 - acc: 0.9989 - val_loss: 0.6381 - val_acc: 0.8681\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0063 - acc: 0.9996 - val_loss: 0.7554 - val_acc: 0.8533\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 2s 108us/step - loss: 0.0060 - acc: 0.9996 - val_loss: 0.6980 - val_acc: 0.8668\n"
     ]
    }
   ],
   "source": [
    "# 使用512 个样本组成的小批量，将模型训练20 个轮次（即对x_train 和y_train 两个张量中的所有样本进行20 次迭代）。与此同时，你还要监控在\n",
    "# 留出的10000 个样本上的损失和精度。你可以通过将验证数据传入validation_data 参数来完成。\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['acc'])\n",
    "history = model.fit(partial_x_train,partial_y_train,epochs=20,batch_size=512,validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "#注意，调用model.fit() 返回了一个History 对象。这个对象有一个成员history，它是一个字典，包含训练过程中的所有数据\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "# dict_keys(['val_acc', 'acc', 'val_loss', 'loss'])\n",
    "# 字典中包含4 个条目，对应训练过程和验证过程中监控的指标。我们将使用Matplotlib 在同一张图上绘制训练损失和验证损失，以及训练精度和验证精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')#'bo' 表示蓝色圆点\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')#'b' 表示蓝色实线\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "print(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制训练精度和验证精度\n",
    "import matplotlib.pyplot as plt\n",
    "plt.clf()#清空图像\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 0. 0. 0.]\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 4s 149us/step - loss: 0.4358 - acc: 0.8208\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.2513 - acc: 0.9098\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 67us/step - loss: 0.1972 - acc: 0.9301\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 0.1667 - acc: 0.9414\n",
      "25000/25000 [==============================] - 4s 156us/step\n",
      "[0.3264573284339905, 0.8702]\n"
     ]
    }
   ],
   "source": [
    "# 如你所见，训练损失每轮都在降低，训练精度每轮都在提升。这就是梯度下降优化的预期结果——你想要最小化的量随着每次迭代越来越小。但验证损失和验证精度\n",
    "# 并非如此：它们似乎在第四轮达到最佳值。这就是我们之前警告过的一种情况：模型在训练数据上的表现越来越好，准确地说，你看到的是过拟合（overfit）\n",
    "\n",
    "#我们从头开始训练一个新的网络，训练4 轮，然后在测试数据上评估模型\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))#创建一个形状为(len(sequences),dimension) 的全部都是零矩阵\n",
    "    #print(results)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.#将results[i] 的指定索引设为1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)#将训练数据向量化\n",
    "x_test = vectorize_sequences(test_data)#将测试数据向量化\n",
    "\n",
    "#样本现在变成了这样：\n",
    "print(x_train[0])\n",
    "#array([ 0., 1., 1., ..., 0., 0., 0.])\n",
    "\n",
    "#你还应该将标签向量化，这很简单。\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "#最终结果如下所示。\n",
    "print(results)\n",
    "#[0.2929924130630493, 0.88327999999999995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16656803],\n",
       "       [0.99984753],\n",
       "       [0.6342311 ],\n",
       "       ...,\n",
       "       [0.09206237],\n",
       "       [0.05418232],\n",
       "       [0.5262962 ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用训练好的网络在新数据上生成预测结果\n",
    "# 训练好网络之后，你希望将其用于实践。你可以用predict 方法来得到评论为正面的可能性大小。\n",
    "model.predict(x_test)\n",
    "#网络对某些样本的结果非常确信（大于等于0.99，或小于等于0.01），但对其他结果却不那么确信（0.6 或0.4）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n",
      "2246\n",
      "[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "#實作路透社数据集\n",
    "# 使用路透社数据集，它包含许多短新闻及其对应的主题，由路透社在1986 年发布。它是一个简单的、广泛使用的文本分类数据集。它包括46 个不同的主题\n",
    "# 加载路透社数据集\n",
    "from keras.datasets import reuters\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "# 与IMDB 数据集一样，参数num_words=10000 将数据限定为前10 000 个最常出现的单词。\n",
    "# 我们有8982 个训练样本和2246 个测试样本。\n",
    "print(len(train_data))\n",
    "#8982\n",
    "print(len(test_data))\n",
    "#2246\n",
    "#与IMDB 评论一样，每个样本都是一个整数列表（表示单词索引）。\n",
    "print(train_data[10])\n",
    "# [1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979,\n",
    "# 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "# 你可以使用与上一个例子相同的代码将数据向量化。\n",
    "\n",
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)#将训练数据向量化\n",
    "x_test = vectorize_sequences(test_data)#将测试数据向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将标签向量化\n",
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)#将训练标签向量化\n",
    "one_hot_test_labels = to_one_hot(test_labels)#将测试标签向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建网络\n",
    "#上一个例子使用了16 维的中间层，但对这个例子来说16 维空间可能太小了，无法学会区分46 个不同的类别。下面将使用维度更大的层，包含64 个单元。\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关于这个架构还应该注意另外两点。\n",
    "#  网络的最后一层是大小为 46 的 Dense 层。这意味着，对于每个输入样本，网络都会输出一个46 维向量。这个向量的每个元素（即每个维度）代表不同\n",
    "#   的输出类别。\n",
    "#  最后一层使用了 softmax 激活。你在 MNIST 例子中见过这种用法。网络将输出在 46个不同输出类别上的概率分布——对于每一个输入样本，网络都会\n",
    "#   输出一个46 维向量，其中output[i] 是样本属于第i 个类别的概率。46 个概率的总和为1。\n",
    "# 对于这个例子，最好的损失函数是categorical_crossentropy（分类交叉熵）。它用于衡量两个概率分布之间的距离，这里两个概率分布分别是网络输出\n",
    "# 的概率分布和标签的真实分布。通过将这两个分布的距离最小化，训练网络可使输出结果尽可能接近真实标签。\n",
    "\n",
    "#编译模型\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 265us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7208 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 147us/step - loss: 1.4452 - acc: 0.6879 - val_loss: 1.3459 - val_acc: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 1.0953 - acc: 0.7651 - val_loss: 1.1708 - val_acc: 0.7430\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 138us/step - loss: 0.8696 - acc: 0.8166 - val_loss: 1.0796 - val_acc: 0.7590\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 0.7034 - acc: 0.8474 - val_loss: 0.9841 - val_acc: 0.7810\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 0.5664 - acc: 0.8800 - val_loss: 0.9411 - val_acc: 0.8030\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 0.4583 - acc: 0.9045 - val_loss: 0.9082 - val_acc: 0.8010\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 156us/step - loss: 0.3697 - acc: 0.9227 - val_loss: 0.9356 - val_acc: 0.7910\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 0.3034 - acc: 0.9311 - val_loss: 0.8913 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 143us/step - loss: 0.2538 - acc: 0.9414 - val_loss: 0.9052 - val_acc: 0.8120\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.2189 - acc: 0.9468 - val_loss: 0.9187 - val_acc: 0.8140\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 0.1878 - acc: 0.9505 - val_loss: 0.9065 - val_acc: 0.8130\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 0.1708 - acc: 0.9524 - val_loss: 0.9324 - val_acc: 0.8100\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 151us/step - loss: 0.1536 - acc: 0.9551 - val_loss: 0.9660 - val_acc: 0.8060\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 135us/step - loss: 0.1393 - acc: 0.9558 - val_loss: 0.9693 - val_acc: 0.8150\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 150us/step - loss: 0.1316 - acc: 0.9559 - val_loss: 1.0229 - val_acc: 0.8030\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 0.1220 - acc: 0.9578 - val_loss: 1.0344 - val_acc: 0.7960\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.1201 - acc: 0.9577 - val_loss: 1.0454 - val_acc: 0.8060\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.1138 - acc: 0.9597 - val_loss: 1.0975 - val_acc: 0.7980\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 0.1116 - acc: 0.9597 - val_loss: 1.0728 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "#验证你的方法我们在训练数据中留出1000 个样本作为验证集。\n",
    "\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]\n",
    "\n",
    "#现在开始训练网络，共20 个轮次\n",
    "\n",
    "history = model.fit(partial_x_train,partial_y_train,epochs=20,batch_size=512,validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 2s 241us/step - loss: 2.5398 - acc: 0.5226 - val_loss: 1.6733 - val_acc: 0.6570\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 131us/step - loss: 1.3712 - acc: 0.7121 - val_loss: 1.2756 - val_acc: 0.7210\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 1.0135 - acc: 0.7785 - val_loss: 1.1301 - val_acc: 0.7540\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.7974 - acc: 0.8257 - val_loss: 1.0543 - val_acc: 0.7580\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 0.6390 - acc: 0.8628 - val_loss: 0.9753 - val_acc: 0.7920\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.5122 - acc: 0.8918 - val_loss: 0.9106 - val_acc: 0.8110\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 150us/step - loss: 0.4127 - acc: 0.9138 - val_loss: 0.8928 - val_acc: 0.8210\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.3358 - acc: 0.9286 - val_loss: 0.8741 - val_acc: 0.8270\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 151us/step - loss: 0.2784 - acc: 0.9374 - val_loss: 0.9362 - val_acc: 0.8020\n",
      "2246/2246 [==============================] - 0s 155us/step\n",
      "[1.0240048084106173, 0.7764915405695499]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=9,\n",
    "batch_size=512,\n",
    "validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "#最终结果如下\n",
    "print(results)\n",
    "#[0.9565213431445807, 0.79697239536954589]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
